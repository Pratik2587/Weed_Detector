{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c24a21b9c4be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Reshape the train, test, val data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = r'/kaggle/input/weed-detection-in-soybean-crops/dataset/dataset/' # Setting the dataset directory\n",
    "classes = ['broadleaf', 'grass', 'soil', 'soybean'] # Setting all the available classes\n",
    "\n",
    "num_file = 1100 # Number of files\n",
    "all_files = []\n",
    "num_data = num_file * len(classes)\n",
    "Y = np.zeros(num_data) # Initialize all output values with 0\n",
    "\n",
    "# Get the files\n",
    "for i, cls in enumerate(classes):\n",
    "  all_files += [f for f in glob.glob(data_dir + cls + '/*.tif')][:num_file]\n",
    "  Y[i * num_file: (i + 1) * num_file] = i # Label all classes with int [0.. len(classes)]\n",
    "\n",
    "image_width = 200\n",
    "image_height = 200\n",
    "image_channel = 3\n",
    "dimension = image_width * image_height * image_channel\n",
    "\n",
    "X = np.ndarray(shape=(num_data, image_width, image_height, image_channel), dtype=np.uint8) # Create a nd array\n",
    "\n",
    "for i, file in enumerate(all_files):\n",
    "  X[i] = cv2.resize(cv2.imread(file), (image_width, image_height)) # Add and load all images\n",
    "\n",
    "# Split training, validation and testing set by creating empty arrays\n",
    "X_train = np.empty(shape=(4000, image_width, image_height, image_channel), dtype=np.uint8)\n",
    "X_val = np.empty(shape=(200, image_width, image_height, image_channel), dtype=np.uint8)\n",
    "X_test = np.empty(shape=(200, image_width, image_height, image_channel), dtype=np.uint8)\n",
    "\n",
    "Y_train = np.empty(4000)\n",
    "Y_val = np.empty(200)\n",
    "Y_test = np.empty(200)\n",
    "\n",
    "# Set all x and y values\n",
    "for i, cls in enumerate(classes):\n",
    "  X_test[50 * i: 50 * (i + 1)] = X[np.where(Y == i)[0][:50]]\n",
    "  X_val[50 * i: 50 * (i + 1)] = X[np.where(Y == i)[0][50:100]]\n",
    "  X_train[1000 * i: 1000 * (i + 1)] = X[np.where(Y == i)[0][100:]]\n",
    "\n",
    "  Y_test[50 * i: 50 * (i + 1)] = i\n",
    "  Y_val[50 * i: 50 * (i + 1)] = i\n",
    "  Y_train[1000 * i: 1000 * (i + 1)] = i\n",
    "\n",
    "# Save some memory by deleting X and Y\n",
    "del Y\n",
    "del X\n",
    "\n",
    "# Select random x and y train data\n",
    "train_indexes = np.random.permutation(X_train.shape[0]) # Create random indexes array with the length of X_train.shape[0]\n",
    "Y_train = Y_train[train_indexes].astype(int) \n",
    "X_train = X_train[train_indexes]\n",
    "\n",
    "# Reshape the train, test, val data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1)).astype('float64')\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1)).astype('float64')\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1)).astype('float64')\n",
    "\n",
    "# Create custom tiny dataset for testing\n",
    "X_tiny = X_train[100:110].astype('float64')\n",
    "Y_tiny = Y_train[100:110].astype(int)\n",
    "num_dev = 500\n",
    "\n",
    "# Create custom dev dataset for testing\n",
    "X_dev = X_train[0:num_dev].astype('float64')\n",
    "Y_dev = Y_train[0:num_dev].astype(int)\n",
    "\n",
    "# Compute the mean image\n",
    "mean_image = np.mean(X_train, axis=0) # axis=0. stack horizontally\n",
    "# Subtract the mean image from train and test data \n",
    "X_train -= mean_image\n",
    "X_val -= mean_image \n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "X_tiny -= mean_image\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"X_val shape\", X_val.shape)\n",
    "print(\"X_dev shape\", X_dev.shape)\n",
    "print(\"X_tiny shape\", X_tiny.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['broadleaf', 'grass', 'soil', 'soybean']\n",
    "n_class = len(classes)\n",
    "samples_per_class = 4\n",
    "\n",
    "# Plot 4 images of each class\n",
    "for Y, cls in enumerate(classes):\n",
    "  indexes = np.flatnonzero(Y == Y_train)\n",
    "  indexes = np.random.choice(indexes, samples_per_class, replace=False)\n",
    "  for i, index, in enumerate(indexes):\n",
    "    plt_index = i * n_class + Y + 1\n",
    "    plt.subplot(samples_per_class, n_class, plt_index)\n",
    "    plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))\n",
    "    if i == 0: plt.title(cls)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "  hidden_size = 200\n",
    "  input_size = image_width * image_height * image_channel\n",
    "  output_size = n_class\n",
    "\n",
    "  \"\"\"\n",
    "  w1: first layer weight\n",
    "  w2: second layer weight\n",
    "  \"\"\"\n",
    "  w1 = 1e-3 * np.random.randn(input_size, hidden_size)\n",
    "  b1 = np.zeros(hidden_size)\n",
    "  w2 = 1e-3 * np.random.randn(hidden_size, output_size)\n",
    "  b2 = np.zeros(output_size)\n",
    "    \n",
    "  alpha = 1e-5\n",
    "  batch_size = 100\n",
    "    \n",
    "  epochs = 500\n",
    "  \n",
    "  def train(self, X, Y, X_val, Y_val):\n",
    "    N, D = X.shape\n",
    "    N_val = X_val.shape[0]\n",
    "    iteration_per_epoch = max(N / self.batch_size, 1)\n",
    "\n",
    "    loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    \n",
    "    for it in range(self.epochs):\n",
    "      sampling = np.random.choice(np.arange(N), self.batch_size, replace=False) # Create random array data\n",
    "\n",
    "      # Getting batches for x and y\n",
    "      X_batch = X[sampling]\n",
    "      Y_batch = Y[sampling]\n",
    "\n",
    "      loss, grads = self.loss(X_batch, Y=Y_batch)\n",
    "      loss_hist.append(loss)\n",
    "\n",
    "      # Make the model learning and reshape the parameters of the network\n",
    "      self.w1 += -1.0 * self.alpha * grads['w1']\n",
    "      self.b1 += -1.0 * self.alpha * grads['b1']\n",
    "      self.w2 += -1.0 * self.alpha * grads['w2']\n",
    "      self.b2 += -1.0 * self.alpha * grads['b2']\n",
    "\n",
    "      if it % 10 == 0:\n",
    "        print('iteration: %d / %d | Loss: %f' % (it, self.epochs, loss))\n",
    "    \n",
    "      if it % iteration_per_epoch == 0:\n",
    "        train_acc = (self.predict(X_batch) == Y_batch).mean()\n",
    "        val_acc = (self.predict(X_val) == Y_val).mean()\n",
    "        train_acc_hist.append(train_acc)\n",
    "        val_acc_hist.append(val_acc)\n",
    "\n",
    "        self.alpha *= 0.95\n",
    "    \n",
    "    return {\n",
    "        'loss_hist': loss_hist,\n",
    "        'train_acc_hist': train_acc_hist,\n",
    "        'val_acc_hist': val_acc_hist\n",
    "    }\n",
    "\n",
    "  def relu(self, z):\n",
    "    return np.maximum(0, z)\n",
    "  \n",
    "  def predict(self, X):\n",
    "    Y_pred = None\n",
    "    layer1 = self.relu(X.dot(self.w1) + self.b1)\n",
    "    scores = layer1.dot(self.w2) + self.b2\n",
    "    Y_pred = np.argmax(scores, axis=1)\n",
    "    return Y_pred\n",
    "\n",
    "  def loss(self, X, Y = None):\n",
    "    N, D = X.shape\n",
    "\n",
    "    # Calculate the loss of our layer1\n",
    "    layer1 = self.relu(X.dot(self.w1) + self.b1)\n",
    "    scores = layer1.dot(self.w2) + self.b2\n",
    "\n",
    "    if (Y is None):\n",
    "      return scores\n",
    "\n",
    "    # Calculate the actual loss\n",
    "    scores -= scores.max()\n",
    "    scores = np.exp(scores)\n",
    "    scores_sumexp = np.sum(scores, axis=1)\n",
    "    softmax = scores / scores_sumexp.reshape(N, 1)\n",
    "    loss = -1.0 * np.sum(np.log(softmax[range(N), Y]))\n",
    "    loss /= N\n",
    "\n",
    "    grads = {}\n",
    "    correct_class_scores = scores[range(N), Y]\n",
    "    softmax[range(N), Y] = -1.0 * (scores_sumexp - correct_class_scores) / scores_sumexp\n",
    "    softmax /= N\n",
    "\n",
    "    grads['w2'] = layer1.T.dot(softmax)\n",
    "    grads['b2'] = np.sum(softmax, axis=0)\n",
    "\n",
    "    hidden = softmax.dot(self.w2.T)\n",
    "\n",
    "    grads['w1'] = X.T.dot(hidden)\n",
    "    grads['b1'] = np.sum(hidden, axis=0)\n",
    "\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "stats = nn.train(X_dev, Y_dev, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((nn.predict(X_test) == Y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.flatnonzero(0 == Y_train)\n",
    "index = np.random.choice(index, 1, replace=False)\n",
    "prediction = nn.predict(X_train[index])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('{} | {}'.format(classes[0], classes[prediction[0]]))\n",
    "plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))\n",
    "\n",
    "index = np.flatnonzero(1 == Y_train)\n",
    "index = np.random.choice(index, 1, replace=False)\n",
    "prediction = nn.predict(X_train[index])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('{} | {}'.format(classes[1], classes[prediction[0]]))\n",
    "plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
